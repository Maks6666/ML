{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maks6666/ML/blob/main/%D0%94%D0%97_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 1\n",
        "Напишіть функцію, яка повертає список фраз з тексту, які відповідають певному шоблону. При необхідності можете добавити власні параметри.\n",
        "\n",
        "Протестуйте функцію на якомусь тексті."
      ],
      "metadata": {
        "id": "D56Rwjf4EXC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "In the quiet village, a small brown cat slept peacefully on the warm sunny roof.\n",
        "The old oak tree stood tall beside the winding river.\n",
        "A bright red apple hung from the branch, glistening in the soft morning light.\n",
        "Nearby, the young boy played with a shiny silver toy car on the grassy green lawn.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "G4Stff_zFQjv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "words = word_tokenize(text)\n",
        "words = [word for word in words if word not in string.punctuation]\n",
        "tags = pos_tag(words)\n",
        "words"
      ],
      "metadata": {
        "id": "-A6TagFqkWn9",
        "outputId": "f5c8ae2c-bdcf-4e80-f858-3af4093d3764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumps',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog',\n",
              " 'The',\n",
              " 'big',\n",
              " 'red',\n",
              " 'balloon',\n",
              " 'floats',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sky']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q svgling"
      ],
      "metadata": {
        "id": "LkZVxPxXm2-H",
        "outputId": "01b7178e-23d0-47ca-f13f-e51aeb104bee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/67.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('tagsets')\n",
        "\n",
        "def get_phrases(text):\n",
        "\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in string.punctuation]\n",
        "\n",
        "    tags = pos_tag(words)\n",
        "\n",
        "    grammar = \"JJNV: {<JJ.*><N.*><V.*>}\"\n",
        "\n",
        "\n",
        "    chunker = RegexpParser(grammar)\n",
        "    tree = chunker.parse(tags)\n",
        "\n",
        "    phrases = []\n",
        "\n",
        "\n",
        "    for subtree in tree.subtrees():\n",
        "        if subtree.label() == \"JJNV\":\n",
        "            phrase = \" \".join([word for word, tag in subtree.leaves()])\n",
        "            phrases.append(phrase)\n",
        "\n",
        "    return phrases\n",
        "\n",
        "phrases = get_phrases(text)\n",
        "print(phrases)\n"
      ],
      "metadata": {
        "id": "VNIwGlzWgFx4",
        "outputId": "c59104c7-fb5a-4f1e-cea1-fd21a15e0ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['brown cat slept', 'warm sunny roof', 'young boy played']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKhZGmq4ciEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}